{
 "metadata": {
  "name": "iterative_analyses.ipynb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# iterative_analyses.ipynb\n",
      "\n",
      "### You should first run the notebooks ``run_this_first.ipynb`` and ``calculate_tau.ipynb``.\n",
      "\n",
      "This script iterates over pi and/or tau. The user choses the start point and end point (up to one billion). The following statistics are calculated and saved.\n",
      "\n",
      "ALWAYS, WITH OFFSET:\n",
      "\n",
      "*Note: since many aggregate statistics start by bouncing around between extreme values, the user can delay recording maxima and minima for the following by specifying a max_min_offset.*\n",
      "\n",
      "* average_max: the position and value every time a new overall maximum average digit value is encountered\n",
      "* average_min: the same, for minimum\n",
      "* cod_max: the positionand value every time a new overall maximum value for the coefficient of determination is encountered. The c.o.d. may be more familiar as the r-squared value, but it is being compared to a model uniform distribution of digits, not to the best-fit line of the current distribution as would occur in regression analysis.\n",
      "* cod_min: the same, for minimum.\n",
      "* count_range_max: the position and value every time a new maximum range between the maximum digit count and the minimum digit count is encountered.\n",
      "* count_range_min: the same, for minimum range between maximum and minimum digit count.\n",
      "\n",
      "ALWAYS, WITHOUT OFFSET:\n",
      "\n",
      "* cod_targets: the position and value the first time the cod attains a value greater than or equal to a decimal consisting of increasing numbers of nines, e.g. 0.9, then 0.99, then 0.999, etc.\n",
      "\n",
      "ONLY IF ``record_and_save`` is set to ``True``:\n",
      "\n",
      "*These statistics never have an offset.*\n",
      "\n",
      "* averages_all: a list of all of the average digit values, by position\n",
      "* cods_all: a list of all the cods, by position\n",
      "* counts_all: a list of all of the counts for every digit at each position. This file can get large.\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def iter_analyze(constants = ['pi', 'tau'], start_position=0, end_position=1000, max_min_offset=12, record_and_save=False):\n",
      "\n",
      "    import time\n",
      "    import json\n",
      "    \n",
      "    def max_and_min(maxes_list, mins_list, value):\n",
      "        if counter >= max_min_offset:\n",
      "            if len(maxes_list) == 0 or value > maxes_list[-1][0]:\n",
      "                maxes_list.append([value, position])\n",
      "            if len(mins_list) == 0 or value < mins_list[-1][0]:\n",
      "                mins_list.append([value, position])\n",
      "    \n",
      "    starttime = time.time()\n",
      "    \n",
      "    for constant in constants:\n",
      "    \n",
      "        #determine files needed\n",
      "        start_file = int (start_position/100000000)\n",
      "        start_offset = start_position % 100000000\n",
      "        end_file = int (end_position/100000000)\n",
      "        end_offset = end_position % 100000000\n",
      "    \n",
      "        file_list = []\n",
      "        for i in range(start_file, end_file+1):\n",
      "            file_list.append('data/' + constant + '100m.dectxt.00%d' % (i))\n",
      "        \n",
      "        if record_and_save:\n",
      "            averages = []\n",
      "            cods = [] #coefficient of determination, a.k.a. r squared\n",
      "            count_ranges = []\n",
      "            counts_all = []\n",
      "            \n",
      "        counts = [0,0,0,0,0,0,0,0,0,0]\n",
      "        \n",
      "        average_maxes = []\n",
      "        average_mins = []\n",
      "        \n",
      "        cod_maxes = []\n",
      "        cod_mins = []\n",
      "        \n",
      "        cod_target = 0.9\n",
      "        cod_targets = []\n",
      "        \n",
      "        count_range_maxes = []\n",
      "        count_range_mins = []\n",
      "        \n",
      "        running_average = 0.0\n",
      "        \n",
      "        countdown = 1000\n",
      "        countdown_interval = int((end_position-start_position)/100)\n",
      "        \n",
      "        #a quick dict just for user messages\n",
      "        msg_dict = {}\n",
      "        i = 0\n",
      "        for filename in file_list:\n",
      "            i += 1\n",
      "            msg_dict[filename] = i\n",
      "        \n",
      "        position = start_position - 1\n",
      "        \n",
      "        for filename in file_list:\n",
      "            \n",
      "            if filename == file_list[0]:\n",
      "                curr_start_offset = start_offset\n",
      "            else:\n",
      "                curr_start_offset = 0\n",
      "            if filename == file_list[-1]:\n",
      "                curr_end_offset = end_offset\n",
      "            else:\n",
      "                curr_end_offset = -1\n",
      "                \n",
      "            with open(filename, 'r') as file_in:\n",
      "                all_digits = file_in.read()\n",
      "            \n",
      "            print \"Processing file %d of %d.\" % (msg_dict[filename], end_file - start_file + 1)\n",
      "            \n",
      "            digits = all_digits[curr_start_offset:curr_end_offset]\n",
      "            \n",
      "            for digitstr in digits:\n",
      "                digit = int(digitstr)\n",
      "                position += 1\n",
      "                counter = position - start_position\n",
      "                if counter % countdown_interval == 0:\n",
      "                    print countdown,\n",
      "                    countdown -= 1\n",
      "                running_average = running_average + (digit - running_average) / (counter + 1)\n",
      "                max_and_min(average_maxes, average_mins, running_average)\n",
      "                \n",
      "                counts[digit]+=1\n",
      "                curr_count_range = max(counts) - min(counts)\n",
      "                max_and_min(count_range_maxes, count_range_mins, curr_count_range)\n",
      "            \n",
      "                ssr = 0\n",
      "                sst = 0\n",
      "                for x in range(10):\n",
      "                   ssr += (counts[x]  - (1.0 * (counter+1) / 10)) ** 2 # sum of square residuals\n",
      "                   sst += counts[x] ** 2                               # sum of square total\n",
      "                curr_cod = 1.0 - (ssr/sst)\n",
      "                max_and_min(cod_maxes, cod_mins, curr_cod)\n",
      "                if curr_cod >= cod_target:\n",
      "                    cod_targets.append([curr_cod,position])\n",
      "                    cod_target = 1.0 - ((1.0 - cod_target) * 0.1)\n",
      "                \n",
      "                if record_and_save:\n",
      "                    averages.append(running_average)\n",
      "                    cods.append(curr_cod)\n",
      "                    count_ranges.append(curr_count_range)\n",
      "                    counts_all.append(counts)\n",
      "                    \n",
      "            print \"Done. Elapsed time %0.1f minutes.\" % ((time.time() - starttime) / 60)\n",
      "            \n",
      "        basename = \"iter_result_\" + constant + \"_%d-%d-off%d_\" % (start_position, end_position, max_min_offset)\n",
      "        basename2 = \"iter_result_\" + constant + \"_%d-%d_\" % (start_position, end_position)\n",
      "                   \n",
      "        with open(basename+'average_maxes', 'w+') as f:\n",
      "            f.write(json.dumps(average_maxes))      \n",
      "        with open(basename+'average_mins', 'w+') as f:\n",
      "            f.write(json.dumps(average_mins))\n",
      "        with open(basename+'cod_maxes', 'w+') as f:\n",
      "            f.write(json.dumps(cod_maxes))\n",
      "        with open(basename+'cod_mins', 'w+') as f:\n",
      "            f.write(json.dumps(cod_mins))\n",
      "        with open(basename+'count_range_maxes', 'w+') as f:\n",
      "            f.write(json.dumps(count_range_maxes))\n",
      "        with open(basename+'count_range_mins', 'w+') as f:\n",
      "            f.write(json.dumps(count_range_mins))\n",
      "        with open(basename+'cod_targets', 'w+') as f:\n",
      "            f.write(json.dumps(cod_targets))\n",
      "        \n",
      "        if record_and_save:\n",
      "            with open(basename2+'averages_all', 'w+') as f:\n",
      "                f.write(json.dumps(averages))\n",
      "            with open(basename2+'cods_all', 'w+') as f:\n",
      "                f.write(json.dumps(cods))\n",
      "            with open(basename2+'count_ranges_all', 'w+') as f:\n",
      "                f.write(json.dumps(count_ranges))\n",
      "            with open(basename2+'counts_all', 'w+') as f:\n",
      "                f.write(json.dumps(counts_all))\n",
      "           \n",
      "    print \"Procedure finished.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "iter_analyze(['tau'], start_position=0, end_position=1000, max_min_offset=0, record_and_save=True)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing file 1 of 1.\n",
        "1000 999 998 997 996 995 994 993 992 991 990 989 988 987 986 985 984 983 982 981 980 979 978 977 976 975 974 973 972 971 970 969 968 967 966 965 964 963 962 961 960 959 958 957 956 955 954 953 952 951 950 949 948 947 946 945 944 943 942 941 940 939 938 937 936 935 934 933 932 931 930 929 928 927 926 925 924 923 922 921 920 919 918 917 916 915 914 913 912 911 910 909 908 907 906 905 904 903 902 901 Done. Elapsed time 0.0 minutes.\n",
        "Procedure finished.\n"
       ]
      }
     ],
     "prompt_number": 23
    }
   ],
   "metadata": {}
  }
 ]
}